---
title: "ClimateWNA data manipulation"
author: "Tom Miller"
date: "September 5, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T,message=F,warning=F)
library(tidyverse)
library(data.table)
library(chron)
library(ggfortify)
```

## Overview
I am trying to wrap up the climate analysis, which has become a real shitshow. There was just (9/5/2018) an email alert that ClimateWNA now includes 2017, which will allow us to add the 2016-17 transition year. So it is a good point to re-assess the climate data and how we interpret the PCs. I will run all of Kevin's PCA code here and recreate the seasonal PCA with the updated data, just so that I have a clear understanding of what Kevin did and how to interpret it. Lastly, I am dropping future climate change projections because I am uncomfortable (for now) projecting into very different future climates. The past is hard enough!

## Tidy up ClimateWNA data
First, read in the historical data from ClimateWNA for the period 1901-2016. This comes from the lat, long, and elevation of the Blue Grama met station (34.335, -106.632, 1669). I can (need to) show elsewhere that ClimateWNA data correlate well with SEV met data. Better to do this with Deep Well, which is the longest SEV met data set. I will do this elsewhere or below. The steps below compute seasonal values (sums or averages) from the raw monthly data, where warm season is May through September and cool season is October through April.
```{r climate dat manip}
SEV_clim <- read.csv("ClimWNA_SEV_1901-2017AMT.csv")

## gather each climate variable into its own df and derive month
BlueGrama_TMax <- SEV_clim %>% 
  filter(ID2 == "BlueGrama") %>% 
  select(Year,Tmax01:Tmax12) %>% 
  gather(Tmax01:Tmax12,key="Month",value="Tmax")%>% 
  mutate(Month = as.integer(str_sub(Month,5,6))) 
BlueGrama_TMin <- SEV_clim %>% 
  filter(ID2 == "BlueGrama") %>% 
  select(Year,Tmin01:Tmin12) %>% 
  gather(Tmin01:Tmin12,key="Month",value="Tmin")%>% 
  mutate(Month = as.integer(str_sub(Month,5,6))) 
BlueGrama_TAve <- SEV_clim %>% 
  filter(ID2 == "BlueGrama") %>% 
  select(Year,Tave01:Tave12) %>% 
  gather(Tave01:Tave12,key="Month",value="Tave")%>% 
  mutate(Month = as.integer(str_sub(Month,5,6))) 
BlueGrama_PPT <- SEV_clim %>% 
  filter(ID2 == "BlueGrama") %>% 
  select(Year,PPT01:PPT12) %>% 
  gather(PPT01:PPT12,key="Month",value="PPT")%>% 
  mutate(Month = as.integer(str_sub(Month,4,5)))

## merge into one, assign transition year and season
BlueGrama_clim <- left_join(left_join(left_join(BlueGrama_TMax,BlueGrama_TMin,by=c("Year","Month")),
                            BlueGrama_TAve,by=c("Year","Month")),
                            BlueGrama_PPT,by=c("Year","Month")) %>% 
  mutate(trans_year = ifelse(Month >=5, Year, Year-1),
         season = ifelse(Month >=5 & Month <=9,"warm","cool")) %>% 
  arrange(Year,Month)%>% 
  group_by(trans_year,season) %>% 
  summarise(max_temp = max(Tmax),
            min_temp = min(Tmin),
            mean_temp = round(mean(Tave),digits=1),
            tot_prcp = sum(PPT)) %>% 
  filter(trans_year>=1901 & trans_year<=2017) %>% 
  mutate(demographic_data = ifelse(trans_year>=2004,T,F))
  
BlueGrama_clim %>% filter(season=="cool") %>% 
ggplot()+
  geom_line(aes(x=trans_year,y=min_temp,color=demographic_data))

```

I am not sure how well I trust the WNA data, just looking at cool season temp minima. The freeze of 2011 barely even stands out but we know this was an extreme, rare event. 

## Compare ClimateWNA to SEV met data
```{r SEV met dat}
dat_SEV1 <- read.csv('C:/Users/tm9/Dropbox/Kevin Czachura senior thesis/Original Work/Data/Sev Meteorology/sev1_meteorology_2001-2005.csv')
dat_SEV2 <- read.csv('C:/Users/tm9/Dropbox/Kevin Czachura senior thesis/Original Work/Data/Sev Meteorology/sev1_meteorology_2006-2010.csv')
dat_SEV3 <- read.csv('C:/Users/tm9/Dropbox/Kevin Czachura senior thesis/Original Work/Data/Sev Meteorology/sev1_meteorology_2011-2015.csv')
dat_SEV4 <- read.csv("C:/Users/tm9/Dropbox/Kevin Czachura senior thesis/Original Work/Data/Sev Meteorology/SEV_hourly_meteorology_2016.csv") 
dat_SEV5 <- read.csv("C:/Users/tm9/Dropbox/Kevin Czachura senior thesis/Original Work/Data/Sev Meteorology/SEV_hourly_meteorology_2017.csv")

##bind all years ##grab Blue Grama (50) and Deep Well (40) met stations 
##convert Julian date to month and day
## I think garbage readings were converted to -999. I am applying my own garbage filters
dat_SEV <- bind_rows(dat_SEV1,dat_SEV2,dat_SEV3,dat_SEV4,dat_SEV5) %>% 
  filter(StationID == 50 | StationID == 40) %>% 
  mutate(Station = ifelse(StationID == 50, "BlueGrama", "DeepWell"),
    Month = as.integer(month.day.year(jul = Julian_Day, origin. = c(month=1,day=0,year=Year))$month),
         Day = month.day.year(jul = Julian_Day, origin. = c(month=1,day=0,year=Year))$day,
         Temp_C = ifelse(Temp_C <= -100 | Temp_C > 100, NA, Temp_C),
         Min_Temp_C = ifelse(Min_Temp_C <= -100 | Min_Temp_C > 100, NA, Min_Temp_C),
         Max_Temp_C = ifelse(Max_Temp_C <= -100 | Max_Temp_C > 100, NA, Max_Temp_C),
         Precipitation = ifelse(Precipitation < 0, NA, Precipitation)) %>% 
  filter(Min_Temp_C != -40.00) %>%
  group_by(Station,Year,Month)
```
Since the raw observations are hourly, we can sort out the problem months by asking where there are fewer than $24 * 28$ observations, which is the number expected in the shortest month (February).
```{r problem months}
dat_SEV %>% 
  group_by(Station,Year,Month) %>% 
  summarise(count = n()) %>% 
  filter(count < 28*24)
```
Most of these are not too bad (ca. 500-600 hours of observion per month, probably still enough to get a good min, mean, max of temp and total precip). Also, it seems that there were a lot of issues with Deep Well in 2015. I am more concerned about this subset with fewer than 500 observation hours (about 20 days). I am going to assign NA values to months with <500 hours of observation. 
```{r find bad months}
SEV_monthly <- dat_SEV %>% 
  group_by(Station,Year,Month) %>% 
  summarise(TAVG = mean(Temp_C, na.rm = T),
            TMAX = max(Max_Temp_C, na.rm = T),
            TMIN = min(Min_Temp_C, na.rm = T),
            PRCP = sum(Precipitation, na.rm = T),
            count = n()) %>% 
  mutate(TAVG = ifelse(count>500,TAVG,NA),
         TMAX = ifelse(count>500,TMAX,NA),
         TMIN = ifelse(count>500,TMIN,NA),
         PRCP = ifelse(count>500,PRCP,NA))
```
Finally, convert to seasons.
```{r SEV seasonal}
SEV_seasonal <- SEV_monthly %>% 
mutate(trans_year = ifelse(Month >=5, Year, Year-1),
         season = ifelse(Month >=5 & Month <=9,"warm","cool")) %>% 
  arrange(Year,Month)%>% 
  group_by(Station,trans_year,season) %>% 
  summarise(max_temp = max(TMAX),
            min_temp = min(TMIN),
            mean_temp = round(mean(TAVG),digits=1),
            tot_prcp = sum(PRCP))
```

Now finally, let's see how well the SEV met data correlate with ClimateWNA. Focus on Deep Well, which has more years of data. Note that below I cut out the 2017 transition year cool season, since the latest monthly estimates (from both data sets) come from December 2017.
```{r SEV WNA correspondence}

SEV_WNA <- left_join(SEV_seasonal %>% filter(Station=="BlueGrama"),
          BlueGrama_clim,
          by=c("trans_year","season")) %>% 
  filter(season=="warm" | trans_year<2017)
#write.csv(SEV_WNA,"SEV_WNA.csv")

ggplot(SEV_WNA %>% filter(season=="warm"))+
  geom_point(aes(x=mean_temp.x,y=mean_temp.y))+
  geom_point(aes(x=min_temp.x,y=min_temp.y))+
  geom_point(aes(x=max_temp.x,y=max_temp.y))

ggplot(SEV_WNA %>% filter(season=="cool"))+
  geom_point(aes(x=mean_temp.x,y=mean_temp.y))+
  geom_point(aes(x=min_temp.x,y=min_temp.y))+
  geom_point(aes(x=max_temp.x,y=max_temp.y))

ggplot(SEV_WNA)+
  geom_point(aes(x=mean_temp.x,y=mean_temp.y))+
  geom_point(aes(x=min_temp.x,y=min_temp.y))+
  geom_point(aes(x=max_temp.x,y=max_temp.y))+
  facet_grid(~season)+
  theme_bw()

ggplot(SEV_WNA)+
  geom_point(aes(x=mean_temp.x,y=mean_temp.y,col=season))+
  geom_point(aes(x=min_temp.x,y=min_temp.y,col=season))+
  geom_point(aes(x=max_temp.x,y=max_temp.y,col=season))+
  theme_bw()

ggplot()+
  geom_point(data=SEV_WNA %>% filter(season=="cool"),
             aes(x=tot_prcp.x,y=tot_prcp.y))+
  geom_point(data=SEV_WNA %>% filter(season=="warm"),
             aes(x=tot_prcp.x,y=tot_prcp.y))+
  theme_bw()

ggplot(SEV_WNA)+
  geom_point(aes(x=tot_prcp.x,y=tot_prcp.y,colour=season))+
  theme_bw()

```

Lastly, compute the correlation coefficients:
```{r SEV WNA cor}

cor(SEV_WNA[,c("mean_temp.x","min_temp.x","max_temp.x","tot_prcp.x")], 
                    SEV_WNA[,c("mean_temp.y","min_temp.y","max_temp.y","tot_prcp.y")], method = "spearman", use = "complete.obs")

```

OK I am satisfied. The upshot of all this is that we should proceed with PCA on ClimateWNA. Though at some point I should do same as above but with Deep Well (more years).

## Principal Components Analysis
I first need to spread the seasonal values, then I can run the PCA.
```{r PCA}
A<-BlueGrama_clim %>% 
  select(trans_year,season,min_temp) %>% 
  spread(key=season,value=min_temp) %>% 
  set_names(c("trans_year","min_temp_cool","min_temp_warm"))
B<-BlueGrama_clim %>% 
  select(trans_year,season,mean_temp) %>% 
  spread(key=season,value=mean_temp) %>% 
  set_names(c("trans_year","mean_temp_cool","mean_temp_warm"))
C<-BlueGrama_clim %>% 
  select(trans_year,season,max_temp) %>% 
  spread(key=season,value=max_temp) %>% 
  set_names(c("trans_year","max_temp_cool","max_temp_warm"))
D<-BlueGrama_clim %>% 
  select(trans_year,season,tot_prcp) %>% 
  spread(key=season,value=tot_prcp) %>% 
  set_names(c("trans_year","tot_prcp_cool","tot_prcp_warm"))

PCA_dat <- left_join(left_join(left_join(A,B),C),D) 
SEV_PCA <- prcomp(PCA_dat[,2:9],center = TRUE, scale. = TRUE)
## find the weight of each climate variable in the PCs
SEV_PCA$rotation
summary(SEV_PCA)
autoplot(SEV_PCA,loadings=T,loadings.label=T)
```

Lastly, write the PCA values to file, to be used in demographic analysis.
```{r write PCA}
out<-data.frame(cbind(PCA_dat$trans_year,SEV_PCA$x))
names(out)[1]<-"Year_t"
#do this only once
#write.csv(out,"climateWNA_PCvalues_out.csv")
#write.csv(data.frame(SEV_PCA$rotation),"climateWNA_PCrotation_out.csv",row.names=T)
#write.csv(data.frame(summary(SEV_PCA)$importance),"climateWNA_variableimportance_out.csv")

```

